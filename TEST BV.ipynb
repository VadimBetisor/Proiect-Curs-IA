{"metadata":{"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"#Importing all libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport json\nfrom torch import optim","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"396292b1-311e-4759-a7df-310df83edd85"},{"cell_type":"code","source":"# Importing libraries related to neurala networks\nimport torch\nimport torch.nn as nn\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom torch.utils import data\nimport torchvision\nimport torchvision.transforms as transforms\nimport PIL.Image as Image\nfrom math import e\nimport torch.nn.functional as F\nimport itertools\nimport random\nfrom torchvision import datasets, transforms","metadata":{},"execution_count":null,"outputs":[],"id":"c567c956-ecde-4561-8e15-bcaa098355fa"},{"cell_type":"code","source":"# Defining the Dataset\nclass SNN_Dataset(data.Dataset):\n    def __init__(self, root, ME_DIR, NOT_ME_DIR):\n        self.root = root\n        ME_PATHS = listdir(ME_DIR)\n        NOT_ME_PATHS = listdir(NOT_ME_DIR)\n        ME_PATHS = [join(ME_DIR, img_path) for img_path in ME_PATHS]\n        NOT_ME_PATHS = [join(NOT_ME_DIR, img_path) for img_path in NOT_ME_PATHS]\n        ME_PAIRS = list(itertools.permutations(ME_PATHS, 2))\n        self.TRIPLETS = list(itertools.product(ME_PAIRS, NOT_ME_PATHS))\n        self.TRIPLETS = [list(triplet) for triplet in self.TRIPLETS]\n        for i in range(len(self.TRIPLETS)):\n            self.TRIPLETS[i] = list(self.TRIPLETS[i])\n            self.TRIPLETS[i][0] = list(self.TRIPLETS[i][0])\n            self.TRIPLETS[i][0].append(self.TRIPLETS[i][1])\n            self.TRIPLETS[i].pop(-1)\n            self.TRIPLETS[i] = self.TRIPLETS[i][0]\n        random.shuffle(self.TRIPLETS)\n    def __getitem__(self, index):\n        img_triplet = [Image.open(img).convert('RGB') for img in self.TRIPLETS[index]]\n        img_triplet = [transforms.Scale((244, 244))(img) for img in img_triplet]\n        img_triplet = [transforms.ToTensor()(img) for img in img_triplet]\n        return img_triplet[0], img_triplet[1], img_triplet[2]\n    def __len__(self):\n        return self.TRIPLETS","metadata":{},"execution_count":null,"outputs":[],"id":"ca6d25d7-1ee0-409d-9226-9647ce1ad85d"},{"cell_type":"code","source":"snn_dataset = SNN_Dataset(r'C:\\Users\\user\\Desktop\\SNN-main\\photos',r'C:\\Users\\user\\Desktop\\SNN-main\\photos\\ME', r'C:\\Users\\user\\Desktop\\SNN-main\\photos\\NOT_ME')","metadata":{},"execution_count":null,"outputs":[],"id":"47895069-74ef-4285-b667-8b4c22ce131f"},{"cell_type":"code","source":"# Creating the data laoder.\nsnn_loader = torch.utils.data.DataLoader(\n    snn_dataset,\n    batch_size=1,\n    num_workers=2\n)","metadata":{},"execution_count":null,"outputs":[],"id":"730ecfb6-ad2c-4656-8c50-555d2a8c27e7"},{"cell_type":"code","source":"# Creating the CNN\nclass CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n        self.maxpool1 = nn.MaxPool2d(3, stride=1)\n        self.conv1_dropuot = nn.Dropout2d(0.5)\n        self.comv2 = nn.Conv2d(16, 32, 3, padding=1)\n        self.conv2_dropuot = nn.Dropout2d(0.5)\n        self.maxpool2 = nn.MaxPool2d(3, stride=1)\n        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n        self.conv3_dropout = nn.Dropout2d(0.5)\n        self.maxpool3 = nn.MaxPool2d(3, stride=1)\n        self.linear1 = nn.Linear(3625216, 32)\n        self.linear2 = nn.Linear(32, 16)\n    def forward(self, x):\n        out = self.conv1_dropuot(self.maxpool1(self.conv1(x)))\n        out = self.conv2_dropuot(self.maxpool2(self.comv2(out)))\n        out = self.conv3_dropout(self.maxpool3(self.conv3(out)))\n        out = out.view(out.size(0), -1)\n        out = self.linear1(out)\n        out = self.linear2(out)\n        return out","metadata":{},"execution_count":null,"outputs":[],"id":"1e3718ec-71d0-4abe-9123-8a07d3f35906"},{"cell_type":"code","source":"# Creatting the model\nmodel = CNN()\n\ndef loos(tested_out, known_out, non_obj_out, alpha):\n    ''' This function is calcultating the loss\n        :param tested_out: tensor\n            The linear representation of the tested image\n        :param known_out: tensor\n            The linear representation of the knwon image\n        :param non_obj_out: tensor\n            The linear representation of the random image\n        :param alpha: float\n            The senzivity parameter\n    '''\n    norm1 = torch.norm(tested_out - known_out, p=2)\n    norm2 = torch.norm(tested_out - non_obj_out, p=2)\n    return max(norm1 - norm2 + alpha, torch.zeros(1, requires_grad=True))","metadata":{},"execution_count":null,"outputs":[],"id":"dbc059dd-1d94-4c77-ba3d-3ec6b91a563d"},{"cell_type":"code","source":"# Definign the optimizer\noptimizer = optim.SGD(model.parameters(), lr=0.000001, momentum=0.5)","metadata":{},"execution_count":null,"outputs":[],"id":"032289f6-83e6-462a-b974-964444bdd2e9"},{"cell_type":"code","source":"# Training process\nfor epoch in range(10):\n    print(\"Epoch {}\".format(epoch))\n    train_loss = 0.0\n    for triplet in snn_dataset:\n        out1 = model(triplet[0].unsqueeze(1).permute(1, 0, 2, 3))\n        out2 = model(triplet[1].unsqueeze(1).permute(1, 0, 2, 3))\n        out3 = model(triplet[2].unsqueeze(1).permute(1, 0, 2, 3))\n        loss = loos(out1, out2, out3, alpha=0.5)\n        loss.backward()\n        optimizer.step()\n        print(loss)\n\nEpoch 0\ntensor(0.5622, grad_fn=<AddBackward0>)\ntensor(0.4224, grad_fn=<AddBackward0>)\ntensor(0.3875, grad_fn=<AddBackward0>)\ntensor(0.6228, grad_fn=<AddBackward0>)\ntensor(0.1484, grad_fn=<AddBackward0>)\ntensor(0.7787, grad_fn=<AddBackward0>)\nEpoch 1\ntensor(0.7224, grad_fn=<AddBackward0>)\ntensor(0.4561, grad_fn=<AddBackward0>)\ntensor(0.4819, grad_fn=<AddBackward0>)\ntensor(0.1999, grad_fn=<AddBackward0>)\ntensor(1.7736, grad_fn=<AddBackward0>)\ntensor(1.1796, grad_fn=<AddBackward0>)\nEpoch 2\ntensor(2.9611, grad_fn=<AddBackward0>)\ntensor(2.2283, grad_fn=<AddBackward0>)\ntensor(3.4101, grad_fn=<AddBackward0>)\ntensor([0.], requires_grad=True)\ntensor([0.], requires_grad=True)\ntensor(1.5980, grad_fn=<AddBackward0>)\nEpoch 3\ntensor(3.2073, grad_fn=<AddBackward0>)\ntensor(3.6162, grad_fn=<AddBackward0>)\ntensor([0.], requires_grad=True)\ntensor(6.8160, grad_fn=<AddBackward0>)\ntensor(4.7230, grad_fn=<AddBackward0>)\ntensor(1.2789, grad_fn=<AddBackward0>)\nEpoch 4\ntensor(0.9604, grad_fn=<AddBackward0>)\ntensor(3.4249, grad_fn=<AddBackward0>)\ntensor([0.], requires_grad=True)\ntensor(1.5595, grad_fn=<AddBackward0>)\ntensor(2.3176, grad_fn=<AddBackward0>)\ntensor(11.1287, grad_fn=<AddBackward0>)\nEpoch 5\ntensor(9.8319, grad_fn=<AddBackward0>)\ntensor(2.0458, grad_fn=<AddBackward0>)\ntensor(3.7131, grad_fn=<AddBackward0>)\ntensor(2.5915, grad_fn=<AddBackward0>)\ntensor(2.2747, grad_fn=<AddBackward0>)\ntensor(2.4474, grad_fn=<AddBackward0>)\nEpoch 6\ntensor([0.], requires_grad=True)\ntensor(0.7385, grad_fn=<AddBackward0>)\ntensor(10.9662, grad_fn=<AddBackward0>)\ntensor(8.5499, grad_fn=<AddBackward0>)\ntensor([0.], requires_grad=True)\ntensor([0.], requires_grad=True)\nEpoch 7\ntensor(5.9020, grad_fn=<AddBackward0>)\ntensor([0.], requires_grad=True)\ntensor(0.5641, grad_fn=<AddBackward0>)\ntensor([0.], requires_grad=True)\ntensor([0.], requires_grad=True)\ntensor(10.7903, grad_fn=<AddBackward0>)\nEpoch 8\ntensor([0.], requires_grad=True)\ntensor([0.], requires_grad=True)\ntensor([0.], requires_grad=True)\ntensor(8.7582, grad_fn=<AddBackward0>)\ntensor([0.], requires_grad=True)\ntensor([0.], requires_grad=True)\nEpoch 9\ntensor(5.6105, grad_fn=<AddBackward0>)\ntensor(3.9385, grad_fn=<AddBackward0>)\ntensor(4.0335, grad_fn=<AddBackward0>)\ntensor(7.8433, grad_fn=<AddBackward0>)\ntensor(4.4903, grad_fn=<AddBackward0>)\ntensor([0.], requires_grad=True)","metadata":{},"execution_count":null,"outputs":[],"id":"c5eebdbe-f5e3-47e5-bcc3-d966d296651b"},{"cell_type":"code","source":"# Saving the model\ntorch.save(model, 'VADIM.pt')","metadata":{},"execution_count":null,"outputs":[],"id":"906715ce-72ad-4d2b-aa68-0b4841608121"}]}