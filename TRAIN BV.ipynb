{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "6fa8c4a0213b3e8e46e64ca221d4ef2f7254b1e53b83d6209b624a99d7aa7db4"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7088/705991134.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "#Importing all libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from torch import optim"
   ]
  },
  {
   "source": [
    "# Importing libraries related to neurala networks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import PIL.Image as Image\n",
    "from math import e\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import random\n",
    "from torchvision import datasets, transforms"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# Defining the Dataset\n",
    "class SNN_Dataset(data.Dataset):\n",
    "    def __init__(self, root, ME_DIR, NOT_ME_DIR):\n",
    "        self.root = root\n",
    "        ME_PATHS = listdir(ME_DIR)\n",
    "        NOT_ME_PATHS = listdir(NOT_ME_DIR)\n",
    "        ME_PATHS = [join(ME_DIR, img_path) for img_path in ME_PATHS]\n",
    "        NOT_ME_PATHS = [join(NOT_ME_DIR, img_path) for img_path in NOT_ME_PATHS]\n",
    "        ME_PAIRS = list(itertools.permutations(ME_PATHS, 2))\n",
    "        self.TRIPLETS = list(itertools.product(ME_PAIRS, NOT_ME_PATHS))\n",
    "        self.TRIPLETS = [list(triplet) for triplet in self.TRIPLETS]\n",
    "        for i in range(len(self.TRIPLETS)):\n",
    "            self.TRIPLETS[i] = list(self.TRIPLETS[i])\n",
    "            self.TRIPLETS[i][0] = list(self.TRIPLETS[i][0])\n",
    "            self.TRIPLETS[i][0].append(self.TRIPLETS[i][1])\n",
    "            self.TRIPLETS[i].pop(-1)\n",
    "            self.TRIPLETS[i] = self.TRIPLETS[i][0]\n",
    "        random.shuffle(self.TRIPLETS)\n",
    "    def __getitem__(self, index):\n",
    "        img_triplet = [Image.open(img).convert('RGB') for img in self.TRIPLETS[index]]\n",
    "        img_triplet = [transforms.Scale((244, 244))(img) for img in img_triplet]\n",
    "        img_triplet = [transforms.ToTensor()(img) for img in img_triplet]\n",
    "        return img_triplet[0], img_triplet[1], img_triplet[2]\n",
    "    def __len__(self):\n",
    "        return self.TRIPLETS"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn_dataset = SNN_Dataset(r'C:\\Users\\user\\Desktop\\SNN-main\\photos',r'C:\\Users\\user\\Desktop\\SNN-main\\photos\\ME', r'C:\\Users\\user\\Desktop\\SNN-main\\photos\\NOT_ME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data laoder.\n",
    "snn_loader = torch.utils.data.DataLoader(\n",
    "    snn_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(3, stride=1)\n",
    "        self.conv1_dropuot = nn.Dropout2d(0.5)\n",
    "        self.comv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv2_dropuot = nn.Dropout2d(0.5)\n",
    "        self.maxpool2 = nn.MaxPool2d(3, stride=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3_dropout = nn.Dropout2d(0.5)\n",
    "        self.maxpool3 = nn.MaxPool2d(3, stride=1)\n",
    "        self.linear1 = nn.Linear(3625216, 32)\n",
    "        self.linear2 = nn.Linear(32, 16)\n",
    "    def forward(self, x):\n",
    "        out = self.conv1_dropuot(self.maxpool1(self.conv1(x)))\n",
    "        out = self.conv2_dropuot(self.maxpool2(self.comv2(out)))\n",
    "        out = self.conv3_dropout(self.maxpool3(self.conv3(out)))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear1(out)\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creatting the model\n",
    "model = CNN()\n",
    "\n",
    "def loos(tested_out, known_out, non_obj_out, alpha):\n",
    "    ''' This function is calcultating the loss\n",
    "        :param tested_out: tensor\n",
    "            The linear representation of the tested image\n",
    "        :param known_out: tensor\n",
    "            The linear representation of the knwon image\n",
    "        :param non_obj_out: tensor\n",
    "            The linear representation of the random image\n",
    "        :param alpha: float\n",
    "            The senzivity parameter\n",
    "    '''\n",
    "    norm1 = torch.norm(tested_out - known_out, p=2)\n",
    "    norm2 = torch.norm(tested_out - non_obj_out, p=2)\n",
    "    return max(norm1 - norm2 + alpha, torch.zeros(1, requires_grad=True))\n",
    "# Definign the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.000001, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training process\n",
    "for epoch in range(10):\n",
    "    print(\"Epoch {}\".format(epoch))\n",
    "    train_loss = 0.0\n",
    "    for triplet in snn_dataset:\n",
    "        out1 = model(triplet[0].unsqueeze(1).permute(1, 0, 2, 3))\n",
    "        out2 = model(triplet[1].unsqueeze(1).permute(1, 0, 2, 3))\n",
    "        out3 = model(triplet[2].unsqueeze(1).permute(1, 0, 2, 3))\n",
    "        loss = loos(out1, out2, out3, alpha=0.5)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 0\n",
    "tensor(0.5622, grad_fn=<AddBackward0>)\n",
    "tensor(0.4224, grad_fn=<AddBackward0>)\n",
    "tensor(0.3875, grad_fn=<AddBackward0>)\n",
    "tensor(0.6228, grad_fn=<AddBackward0>)\n",
    "tensor(0.1484, grad_fn=<AddBackward0>)\n",
    "tensor(0.7787, grad_fn=<AddBackward0>)\n",
    "Epoch 1\n",
    "tensor(0.7224, grad_fn=<AddBackward0>)\n",
    "tensor(0.4561, grad_fn=<AddBackward0>)\n",
    "tensor(0.4819, grad_fn=<AddBackward0>)\n",
    "tensor(0.1999, grad_fn=<AddBackward0>)\n",
    "tensor(1.7736, grad_fn=<AddBackward0>)\n",
    "tensor(1.1796, grad_fn=<AddBackward0>)\n",
    "Epoch 2\n",
    "tensor(2.9611, grad_fn=<AddBackward0>)\n",
    "tensor(2.2283, grad_fn=<AddBackward0>)\n",
    "tensor(3.4101, grad_fn=<AddBackward0>)\n",
    "tensor([0.], requires_grad=True)\n",
    "tensor([0.], requires_grad=True)\n",
    "tensor(1.5980, grad_fn=<AddBackward0>)\n",
    "Epoch 3\n",
    "tensor(3.2073, grad_fn=<AddBackward0>)\n",
    "tensor(3.6162, grad_fn=<AddBackward0>)\n",
    "tensor([0.], requires_grad=True)\n",
    "tensor(6.8160, grad_fn=<AddBackward0>)\n",
    "tensor(4.7230, grad_fn=<AddBackward0>)\n",
    "tensor(1.2789, grad_fn=<AddBackward0>)\n",
    "Epoch 4\n",
    "tensor(0.9604, grad_fn=<AddBackward0>)\n",
    "tensor(3.4249, grad_fn=<AddBackward0>)\n",
    "tensor([0.], requires_grad=True)\n",
    "tensor(1.5595, grad_fn=<AddBackward0>)\n",
    "tensor(2.3176, grad_fn=<AddBackward0>)\n",
    "tensor(11.1287, grad_fn=<AddBackward0>)\n",
    "Epoch 5\n",
    "tensor(9.8319, grad_fn=<AddBackward0>)\n",
    "tensor(2.0458, grad_fn=<AddBackward0>)\n",
    "tensor(3.7131, grad_fn=<AddBackward0>)\n",
    "tensor(2.5915, grad_fn=<AddBackward0>)\n",
    "tensor(2.2747, grad_fn=<AddBackward0>)\n",
    "tensor(2.4474, grad_fn=<AddBackward0>)\n",
    "Epoch 6\n",
    "tensor([0.], requires_grad=True)\n",
    "tensor(0.7385, grad_fn=<AddBackward0>)\n",
    "tensor(10.9662, grad_fn=<AddBackward0>)\n",
    "tensor(8.5499, grad_fn=<AddBackward0>)\n",
    "tensor([0.], requires_grad=True)\n",
    "tensor([0.], requires_grad=True)\n",
    "Epoch 7\n",
    "tensor(5.9020, grad_fn=<AddBackward0>)\n",
    "tensor([0.], requires_grad=True)\n",
    "tensor(0.5641, grad_fn=<AddBackward0>)\n",
    "tensor([0.], requires_grad=True)\n",
    "tensor([0.], requires_grad=True)\n",
    "tensor(10.7903, grad_fn=<AddBackward0>)\n",
    "Epoch 8\n",
    "tensor([0.], requires_grad=True)\n",
    "tensor([0.], requires_grad=True)\n",
    "tensor([0.], requires_grad=True)\n",
    "tensor(8.7582, grad_fn=<AddBackward0>)\n",
    "tensor([0.], requires_grad=True)\n",
    "tensor([0.], requires_grad=True)\n",
    "Epoch 9\n",
    "tensor(5.6105, grad_fn=<AddBackward0>)\n",
    "tensor(3.9385, grad_fn=<AddBackward0>)\n",
    "tensor(4.0335, grad_fn=<AddBackward0>)\n",
    "tensor(7.8433, grad_fn=<AddBackward0>)\n",
    "tensor(4.4903, grad_fn=<AddBackward0>)\n",
    "tensor([0.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "torch.save(model, 'VADIM.pt')"
   ]
  }
 ]
}